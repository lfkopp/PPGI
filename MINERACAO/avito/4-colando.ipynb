{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/_dados/_avito/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        item_id       user_id                 region              city  \\\n",
      "0  b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
      "1  2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
      "2  ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
      "3  02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
      "4  7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
      "\n",
      "  parent_category_name               category_name  \\\n",
      "0          Личные вещи  Товары для детей и игрушки   \n",
      "1      Для дома и дачи           Мебель и интерьер   \n",
      "2  Бытовая электроника               Аудио и видео   \n",
      "3          Личные вещи  Товары для детей и игрушки   \n",
      "4            Транспорт                  Автомобили   \n",
      "\n",
      "                       param_1     param_2 param_3                  title  \\\n",
      "0    Постельные принадлежности           0       0  Кокоби(кокон для сна)   \n",
      "1                       Другое           0       0      Стойка для Одежды   \n",
      "2  Видео, DVD и Blu-ray плееры           0       0         Philips bluray   \n",
      "3         Автомобильные кресла           0       0             Автокресло   \n",
      "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
      "\n",
      "                                         description    price  \\\n",
      "0  Кокон для сна малыша,пользовались меньше месяц...    400.0   \n",
      "1          Стойка для одежды, под вешалки. С бутика.   3000.0   \n",
      "2  В хорошем состоянии, домашний кинотеатр с blu ...   4000.0   \n",
      "3                             Продам кресло от0-25кг   2200.0   \n",
      "4                           Все вопросы по телефону.  40000.0   \n",
      "\n",
      "   item_seq_number activation_date user_type  \\\n",
      "0                2      2017-03-28   Private   \n",
      "1               19      2017-03-26   Private   \n",
      "2                9      2017-03-20   Private   \n",
      "3              286      2017-03-25   Company   \n",
      "4                3      2017-03-16   Private   \n",
      "\n",
      "                                               image  image_top_1  \\\n",
      "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...       1008.0   \n",
      "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...        692.0   \n",
      "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...       3032.0   \n",
      "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...        796.0   \n",
      "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...       2264.0   \n",
      "\n",
      "   deal_probability  \n",
      "0           0.12789  \n",
      "1           0.00000  \n",
      "2           0.43177  \n",
      "3           0.80323  \n",
      "4           0.20797  \n",
      "[RangeIndex(start=0, stop=1503424, step=1), Index(['item_id', 'user_id', 'region', 'city', 'parent_category_name',\n",
      "       'category_name', 'param_1', 'param_2', 'param_3', 'title',\n",
      "       'description', 'price', 'item_seq_number', 'activation_date',\n",
      "       'user_type', 'image', 'image_top_1', 'deal_probability'],\n",
      "      dtype='object')]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(dir + 'train.csv').fillna(0)\n",
    "test = pd.read_csv(dir + 'test.csv').fillna(0)\n",
    "\n",
    "print(train.head())\n",
    "print(train.axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             price  item_seq_number  image_top_1\n",
      "0            400.0                2       1008.0\n",
      "1           3000.0               19        692.0\n",
      "2           4000.0                9       3032.0\n",
      "3           2200.0              286        796.0\n",
      "4          40000.0                3       2264.0\n",
      "5           1300.0                9        796.0\n",
      "6          11000.0              125       2823.0\n",
      "7            500.0               61        567.0\n",
      "8            500.0               85        415.0\n",
      "9            400.0              136         46.0\n",
      "10         18000.0                6       1396.0\n",
      "11             1.0                4        119.0\n",
      "12            70.0               15       1040.0\n",
      "13          2500.0               47       2849.0\n",
      "14          5000.0                6       2133.0\n",
      "15           800.0               86        408.0\n",
      "16        140000.0              201       1118.0\n",
      "17           500.0                9        983.0\n",
      "18          1000.0                4         95.0\n",
      "19        100000.0                5          0.0\n",
      "20       1748000.0              461       2011.0\n",
      "21          2600.0               33          0.0\n",
      "22        249000.0               12       2264.0\n",
      "23          1300.0               59         87.0\n",
      "24             0.0              310        843.0\n",
      "25          1500.0              309        957.0\n",
      "26          1000.0               59       1420.0\n",
      "27          1500.0                8        436.0\n",
      "28          1000.0               12        618.0\n",
      "29           200.0               20         63.0\n",
      "...            ...              ...          ...\n",
      "1503394     2000.0                5       1460.0\n",
      "1503395    20000.0               41       1142.0\n",
      "1503396        0.0               32       2514.0\n",
      "1503397      450.0               36        569.0\n",
      "1503398      500.0                8        523.0\n",
      "1503399      300.0                2       2286.0\n",
      "1503400      400.0               12       2853.0\n",
      "1503401      250.0                6        118.0\n",
      "1503402   720000.0               61       1118.0\n",
      "1503403      500.0               23         93.0\n",
      "1503404  1300000.0                1       1055.0\n",
      "1503405     3000.0               39        821.0\n",
      "1503406     3000.0              259       1348.0\n",
      "1503407      300.0               33         53.0\n",
      "1503408  1600000.0               24       2221.0\n",
      "1503409      480.0              145        127.0\n",
      "1503410     3000.0               26        387.0\n",
      "1503411      150.0               17        590.0\n",
      "1503412      150.0               78       2402.0\n",
      "1503413     8000.0               77       2336.0\n",
      "1503414     7000.0                8       1442.0\n",
      "1503415  1850000.0                6       2221.0\n",
      "1503416      200.0               89        494.0\n",
      "1503417   160000.0               13       2264.0\n",
      "1503418      500.0               10        387.0\n",
      "1503419      300.0                7         88.0\n",
      "1503420      200.0                1       1191.0\n",
      "1503421        0.0               50       1202.0\n",
      "1503422      350.0               33         87.0\n",
      "1503423     1500.0               18        979.0\n",
      "\n",
      "[1503424 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train = train[['price', 'item_seq_number', 'image_top_1']]\n",
    "x_test = test[['price', 'item_seq_number', 'image_top_1']]\n",
    "y_train = train.deal_probability\n",
    "#y_test = test.deal_probability\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrFull = linear_model.LinearRegression()\n",
    "lrFull.fit(x_train, y_train)\n",
    "predictions_full = lrFull.predict(x_test)\n",
    "\n",
    "# mean squared error on full dataset logistic regression\n",
    "#meanSquaredError = np.sum(np.square(x_test - predictions_full))/predictions_full.size\n",
    "#rootMeanSquaredError = math.sqrt(meanSquaredError)\n",
    "#print('Full dataset root mean squared error: ', rootMeanSquaredError)\n",
    "\n",
    "groupableColumnLabels = ['region', 'city', 'parent_category_name', 'category_name', 'user_type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building regression models region\n",
      "Building regression models city\n",
      "Building regression models parent_category_name\n",
      "Building regression models category_name\n",
      "Building regression models user_type\n"
     ]
    }
   ],
   "source": [
    "groupModelsDict = {}\n",
    "\n",
    "for groupableColumnLabel in groupableColumnLabels:\n",
    "    print('Building regression models ' + groupableColumnLabel)\n",
    "    # split our dataframe into a set of dataframes for each parent_category\n",
    "    train_grouping = train.groupby(groupableColumnLabel)\n",
    "    train_groups_dict = {}\n",
    "    [train_groups_dict.__setitem__(x,train_grouping.get_group(x)) for x in train_grouping.groups]\n",
    "\n",
    "    # build our set of regression models one for each parent_category_name\n",
    "    regression_models_dict = {}\n",
    "    for key, train_group in train_groups_dict.items():\n",
    "        lr = linear_model.LinearRegression()\n",
    "        lr.fit(train_group[['price', 'item_seq_number', 'image_top_1']], train_group.deal_probability)\n",
    "        regression_models_dict[key] = lr\n",
    "\n",
    "    groupModelsDict[groupableColumnLabel] = regression_models_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n"
     ]
    }
   ],
   "source": [
    "# iterate over all rows in our test data and build a new row of predictions, one for each category column\n",
    "print('Making predictions')\n",
    "predictions = []\n",
    "for index, row in test.iterrows():\n",
    "    row_data = np.reshape([row['price'], row['item_seq_number'], row['image_top_1']], (1,-1))\n",
    "    \n",
    "    rowPredictions = []\n",
    "    for groupableColumnLabel in groupableColumnLabels:\n",
    "        groupableColumnValue = row[groupableColumnLabel]\n",
    "        # if a model is missing for whatever reason pick up the full model to at least get a number\n",
    "        if groupableColumnValue in regression_models_dict:\n",
    "            prediction = groupModelsDict[groupableColumnLabel][groupableColumnValue].predict(row_data)\n",
    "        else:\n",
    "            prediction = lrFull.predict(row_data)\n",
    "        rowPredictions.append(min(max(0,prediction[0]),1))\n",
    "\n",
    "    predictions.append(rowPredictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:305: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(np.array(a, dtype=dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18144076623748662, 0.0933816898604227, 0.2233659307700773, 0.09249090484752788, 0.13733644023733252, 0.15492572725946768, 0.0791600754844388, 0.17046339676101405, 0.175650088066411, 0.09709974111229412, 0.09304700328514405, 0.21051460277528197, 0.15492050849331024, 0.12225830539424173, 0.15267680893663244, 0.18988164967618035, 0.19377470463346094, 0.09470365029541246, 0.09712735352925676, 0.13316863303442925, 0.11321370562228215, 0.17660900385440603, 0.14462338188143686, 0.09670204471459604, 0.1397877799425084, 0.11542825310799325, 0.22118741999822997, 0.21294934610545693, 0.12068708069592995, 0.15014909002261997, 0.09331474734237409, 0.0930531515894683, 0.1334518127947145, 0.14727134267622363, 0.14122268908321622, 0.04168115877748797, 0.19595572331842423, 0.09519251974749804, 0.14322836650816045, 0.12257372290701901, 0.14091995624267603, 0.17524116679945095, 0.14357998662772148, 0.11022044102038325, 0.12872659645172407, 0.16424368410288193, 0.1577988502495538, 0.1121411372636054, 0.13751432630226276, 0.21526356471099015, 0.09339501415990016, 0.16032001412404792, 0.14692775185632295, 0.19098571350447402, 0.1899694981531143, 0.1654606790777512, 0.09398841959953919, 0.15543561805919598, 0.09336833857746828, 0.13509511739526103, 0.09312640871504609, 0.09485719041561692, 0.1186713720420757, 0.09654381902038361, 0.10931244269364741, 0.13634584094823735, 0.1431399981290834, 0.19288095956237064, 0.11738579767502864, 0.053253145357937855, 0.12160594278620565, 0.22709137235783114, 0.1839220127709187, 0.20321705461910186, 0.1538776854920276, 0.09564814956339081, 0.0948640314385045, 0.09168124938791013, 0.09225764916821949, 0.22197689095179776, 0.09581291416463265, 0.18069423195036646, 0.19197528812810338, 0.19407386135806265, 0.13503005654175498, 0.11878320961555283, 0.15008052300514357, 0.14411332352348025, 0.1433479371769882, 0.10888451625479081, 0.21864017792534374, 0.185893869120192, 0.09738981642756116, 0.11798541878476661, 0.15433702423990894, 0.1592589426712204, 0.22575975658167655, 0.11037590463676818, 0.12844360002163502, 0.1635473820652199]\n"
     ]
    }
   ],
   "source": [
    "#meanPredictions = [sum(p)/5 for p in predictions] \n",
    "\n",
    "\n",
    "#meanPredictions = [np.median(p) for p in predictions]\n",
    "from scipy import stats\n",
    "meanPredictions = [stats.gmean(p) for p in predictions]\n",
    "\n",
    "\n",
    "# mean squared error on individual parent_category logistic regression\n",
    "#meanSquaredError = np.sum(np.square(x_test - meanPredictions))/len(meanPredictions)\n",
    "#rootMeanSquaredError = math.sqrt(meanSquaredError)\n",
    "print(meanPredictions[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir + 'submissions/cola2.csv', 'w') as f:\n",
    "    f.write('item_id,deal_probability\\n')\n",
    "    label      = test['item_id'].values\n",
    "    for label_, predict_ in zip(label, meanPredictions):\n",
    "        p = str(min(1,max(0,float(predict_))))\n",
    "        f.write(str(label_) + ',' + p + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
