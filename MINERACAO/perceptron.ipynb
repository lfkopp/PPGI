{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HmJ02x6qWTr0"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PNhQZ0piWTr5"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, learning_rate = 0.1):\n",
    "        self._input_size = 0\n",
    "        self._output_size = 0\n",
    "        self._weights = None\n",
    "        self.b = None\n",
    "        self._num_samples = 0\n",
    "        self._lr = learning_rate\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, num_epochs = 100, batch_size=None, verbose=False):\n",
    "        if type(X) is not np.ndarray:\n",
    "            raise Exception('X deve ser uma matrix do tipo numpy.ndarray')\n",
    "\n",
    "        if type(y) is not np.ndarray:\n",
    "            raise Exception('y deve ser um vetor do tipo numpy.ndarray')\n",
    "    \n",
    "        \n",
    "        # hot encode y caso ele não venha neste formato\n",
    "        if len(y.shape) == 1: # se só for um vetor então o shape só vai retornar um valor\n",
    "            old_y = y.copy()\n",
    "            num_class = len(set(old_y))\n",
    "            \n",
    "            # transforma cada y em um vetor do tamanho do número de classes\n",
    "            y = np.zeros((old_y.shape[0], 3))\n",
    "\n",
    "            # seta para 1 as posições dos perceptrons correspondentes as classes\n",
    "            for i in xrange(old_y.shape[0]):\n",
    "                posi = old_y[i]\n",
    "                y[i][posi] = 1\n",
    "        \n",
    "      \n",
    "        # batch size é o número de elementos que serão usados em cada época pra atualizar o peso\n",
    "        # caso não seja definido, vou utilizar todos os dados de treinamento disponíveis\n",
    "        if batch_size is None:\n",
    "            batch_size = X.shape[0]\n",
    "        \n",
    "        \n",
    "        # armazenando parâmetros dos dados\n",
    "        self._num_samples = X.shape[0]\n",
    "        self._input_size  = X.shape[1]\n",
    "        self._output_size = y.shape[1]\n",
    "        \n",
    "        # cada neurônio vai ter um conjunto de pesos igual ao número de entradas, \n",
    "        self._weights =  np.random.rand(self._output_size, self._input_size)\n",
    "        \n",
    "        # cada neurônio tem seu próprio bias\n",
    "        self._b =  np.ones(self._output_size)\n",
    "        \n",
    "        \n",
    "        # aqui inicializa o treinamento\n",
    "        for i in range(num_epochs):\n",
    "\n",
    "            # pego um conjunto de posições representando elemento da amostra igual ao tamanho do batch size\n",
    "            posi_to_sample = np.random.randint(0, self._num_samples, batch_size)\n",
    "            for posi in posi_to_sample:\n",
    "                \n",
    "                # obtendo um elemento específico                 \n",
    "                x = X[posi]\n",
    "                y_expected = y[posi]\n",
    "\n",
    "                # calculando Z\n",
    "                Z = np.dot(self._weights, x) + self._b\n",
    "\n",
    "                #  calculando a saída dos neurônios\n",
    "                y_hat = self._activation_function(Z)\n",
    "\n",
    "                # calculando parte do gradiente            \n",
    "                error = (y_hat  - y_expected)\n",
    "                activation_derivative = self._activation_function_derivative(Z)\n",
    "                delta =  error * activation_derivative # delta é só parte da derivada, vou gerar o gradiente completo abaixo\n",
    "                                \n",
    "                #  calculando o gradiente para cada neurônio e atualizando seus pesos\n",
    "                for k in range(self._output_size):        \n",
    "                    \n",
    "                    gradient_w = (1.0/batch_size) * np.dot(delta[k] , x) # como troquei a minha função de erro pra erro médio, o gradiente fica com 1/n\n",
    "                    gradient_b = (1.0/batch_size) * delta[k]\n",
    "\n",
    "                    # finalmente atualizando os pesos\n",
    "                    self._weights[k] = self._weights[k] - (self._lr * gradient_w)\n",
    "                    self._b[k] = self._b[k] - (self._lr * gradient_b)\n",
    "            \n",
    "            \n",
    "            # pra não imprimir sempre, vou mostrar acc a cada 10 iterações\n",
    "            if verbose and (i + 1) % 10 == 0:\n",
    "                print (\"Epoch[%d]: acc: %f \" %(i+1,  self._acc(X, y) ))\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Z é um vetor, cada neurônio vai ter uma saida, portando, o shape de Z é igual a (num_exemplos, num_classes)\n",
    "        Z = np.array([ np.dot(self._weights, x) + self._b  for x in X])\n",
    "        \n",
    "        # aplicando a função de ativação\n",
    "        output = self._activation_function(Z)\n",
    "        \n",
    "        # como o y gerado é um vetor, estou retornando somente as classes relacionadas\n",
    "        return np.argmax(output, axis=1)\n",
    "        \n",
    "    \n",
    "    def _activation_function(self, Z):\n",
    "        return 1.0 / (1.0 + np.e**(-Z))\n",
    "    \n",
    "    def _activation_function_derivative(self, Z):\n",
    "        res_activation = self._activation_function(Z)\n",
    "        return res_activation * (1 - res_activation) \n",
    "    \n",
    "    \n",
    "    def _acc(self, X, y):\n",
    "        count = 0\n",
    "        y_hat = self.predict(X)\n",
    "        for i in range(len(y)):\n",
    "            if np.argmax(y[i]) == y_hat[i]:\n",
    "                count += 1\n",
    "\n",
    "        return float(count) / len(y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2584
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1602,
     "status": "ok",
     "timestamp": 1525390508743,
     "user": {
      "displayName": "Victor Garritano",
      "photoUrl": "//lh3.googleusercontent.com/-hA5KLMXLdZA/AAAAAAAAAAI/AAAAAAAADZA/wNQbKvZo3KI/s50-c-k-no/photo.jpg",
      "userId": "115570807724700621686"
     },
     "user_tz": 180
    },
    "id": "1BgAruyaWTr-",
    "outputId": "02803197-29f0-4880-9be6-d0dc8e939356"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-880ba8b12aad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpercep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mpercep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# avaliando com dados não vistos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-82985fa9ac58>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, num_epochs, batch_size, verbose)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# seta para 1 as posições dos perceptrons correspondentes as classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0mposi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mposi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# X = StandardScaler().fit_transform(X) # descomente esta linha pra melhorar o resultado, acredito que fique em média mais estável\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "percep = Perceptron(learning_rate=0.2)\n",
    "percep.fit(X_train, y_train, num_epochs=1000, batch_size=32, verbose=True)\n",
    "\n",
    "# avaliando com dados não vistos\n",
    "print (\"\\n\\n\")\n",
    "print (\"#\" * 30)\n",
    "y_hat = percep.predict(X_test)\n",
    "print (\"ACC-TEST: \", accuracy_score(y_hat, y_test))\n",
    "print (\"#\" * 30)\n",
    "for i in range(len(y_hat)):\n",
    "    print (\"y_esperado: %d -- y_obtido: %d \" %(y_test[i], y_hat[i]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i0XfPMMAWzbw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "perceptron.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
