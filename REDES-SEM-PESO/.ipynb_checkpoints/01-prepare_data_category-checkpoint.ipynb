{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/_dados/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(dir + 'train.csv', sep=',',index_col=0, dtype={11:'str',12:'str'})\n",
    "test = pd.read_csv(dir + 'test.csv', sep=',',index_col=0, dtype={11:'str',12:'str'})\n",
    "resources = pd.read_csv(dir + 'resources.csv', sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test.columns,'\\n',train.columns,'\\n',resources.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('project_subject_categories')['project_is_approved'].mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['project_subject_categories'] =  train['project_subject_categories'].str.replace('Warmth,','Warmth').str.replace(', ',',').str.replace('& ','').str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['cat1','cat2']] = train['project_subject_categories'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('cat1')['project_is_approved'].mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['cat1','cat2'])['project_is_approved'].mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources['total'] = resources.quantity * resources.price\n",
    "expenses = resources.groupby('id')['total'].sum()\n",
    "expenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_items = resources.groupby('id')['total'].count()\n",
    "number_of_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.join(expenses)\n",
    "train2 = train2.join(number_of_items,rsuffix='1')\n",
    "train2.rename(columns={'total1':'qnty'}, inplace=True)\n",
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = train2.groupby(round(train2['qnty']/5,0)*5)['project_is_approved'].mean()\n",
    "plt.plot(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['total_rounded'] = round(train2['total'],-2)\n",
    "t = train2.groupby(round(train2['total_rounded']/200,0)*200)['project_is_approved'].mean()\n",
    "plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['full_text'] = train2['project_essay_1'].astype(str)+train2['project_essay_2'].astype(str)+train2['project_essay_3'].astype(str)+train2['project_essay_4'].astype(str)\n",
    "train2['full_text'] = train2['full_text'].str.replace(\"\\\\\\\\r\\\\\\\\n\",' ').str.replace(\"\\\\\",'').str.replace(\"\\'\",'').str.replace(\"nannan\",'').str.replace('\\\"','').str.upper()\n",
    "\n",
    "train2['full_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for x in train2.groupby('cat1')['cat1'].head(1):\n",
    "    if x not in groups: groups.append(x)\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for group in groups:\n",
    "    print(group)\n",
    "    train3 = train2[train2['cat1'] == group]\n",
    "    text = train3.index +';'+ train3['project_is_approved'].astype(str) +';'+ train3['cat1'].astype(str) +';'+ train3['full_text'].astype(str)\n",
    "\n",
    "    with open(dir+'/consolidated_'+group+'_1.txt', 'w') as t1: pass\n",
    "    with open(dir+'/consolidated_'+group+'_0.txt', 'w') as t0: pass\n",
    "    with open(dir+'/consolidated_'+group+'_text.txt', 'w') as ct: pass\n",
    "\n",
    "    with open(dir+'consolidated_'+group+'_1.txt', 'w+') as t1:\n",
    "        with open(dir+'consolidated_'+group+'_text.txt', 'w+') as ct:\n",
    "            with open(dir+'consolidated_'+group+'_0.txt', 'w+') as t0:\n",
    "                for line in text:\n",
    "                    try:\n",
    "                        idx,approved,g,line = line.split(';',3)\n",
    "                        with open(dir+'group\\_' group +'_'+ idx +'.txt', 'w') as f:\n",
    "                            clean_line = line.upper()\n",
    "                            clean_line = re.sub(\"\\\\\\\\[RNT]\", \"\", clean_line)\n",
    "                            clean_line = re.sub(\"[^A-Z ]+\", \" \", clean_line)\n",
    "                            clean_line = re.sub(\"\\s\\s+\", \" \", clean_line)\n",
    "                            clean_line = re.sub(\"NANNAN\", \"\", clean_line)\n",
    "                            ct.write(str(idx)+';'+str(clean_line) + '\\n')\n",
    "                            con = Counter(clean_line.split()).items()\n",
    "                            for item in con:\n",
    "                                a,b = item\n",
    "                                f.write(str(a) + ' ' + str(b) + '\\n')\n",
    "                                if approved == '1':\n",
    "                                    t1.write(str(a) + ' ' + str(b) + '\\n')\n",
    "                                else:\n",
    "                                    t0.write(str(a) + ' ' + str(b) + '\\n')\n",
    "                    except:\n",
    "                        print('.', end='',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    with open(dir+'consolidado_'+group+'_0.txt', 'r') as t0:\n",
    "        sorted_file = sorted(t0)\n",
    "    with open(dir+'consolidado_'+group+'_0_sorted.txt', 'w') as f:\n",
    "        f.writelines(sorted_file)\n",
    "    with open(dir+'consolidado_'+group+'_1.txt', 'r') as t1:\n",
    "        sorted_file = sorted(t1)\n",
    "    with open(dir+'consolidado_'+group+'_1_sorted.txt', 'w') as f:\n",
    "        f.writelines(sorted_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved = pd.read_csv(dir+'consolidado_'+group+'_1_sorted.txt', sep = ' ', header=None)\n",
    "not_approved = pd.read_csv(dir+'consolidado_'+group+'_0_sorted.txt', sep = ' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asum = approved.groupby(0)[1].sum()\n",
    "bsum = not_approved.groupby(0)[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acount = approved.groupby(0)[1].count()\n",
    "bcount = not_approved.groupby(0)[1].count()\n",
    "\n",
    "a = len(acount)\n",
    "b = len(bcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.concat([acount,asum,bcount,bsum], keys=['approved_count','approved_sum','not_approved_count',\n",
    "                                               'not_approved_sum'], axis=1).fillna(0)\n",
    "c['sum_count'] = c['approved_count'] + c['not_approved_count']\n",
    "c['sum_sum'] = c['approved_sum'] + c['not_approved_sum']\n",
    "c = c[(c['sum_count'] > 3) & (c['not_approved_sum'] >1)]  \n",
    "c['importance'] = (c['approved_count']*b - c['not_approved_count']*a) / (c['sum_count']*(a+b))\n",
    "c['importance_sq'] = c['importance']  * c['importance'] \n",
    "c.sort_values('importance_sq', ascending=False, inplace=True)\n",
    "c.to_pickle('DONORSCHOOSE\\words.pickle')\n",
    "c = c.head(16000)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_pickle('DONORSCHOOSE\\words.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[c.importance <0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
